 # QHS server 16T ssd:
 (1)cd /data/xuh3
 (2) df -h data # check the space of data directory
 (3) cp -avr $HOME/projects/data/tcga_stad_slide/wsis/ /data/xuh3 # copy data from source to destination


1) when you intall some packages on linux server but encounter the permiss errors, try this

->pip install <libname> --user
e.g. pip install imageio --user
e.g., pip3.5 install scikit-image --user --upgrade

2) when you intall packages for a certain pathon, try this
-> python3.5 -m pip install imageio --user

uninstall packages installed on our server:
-> pip3.5 unstalll torchmeta

check version of installed packages:
->pip3.5 list
or 
->pip3.5 list | grep torch

3) check gpu id from the terminal
-> nvidia-smi

4) linux server terminal command to check numpy verion, try this:
-> python3.5 -c "import numpy; print(numpy.__version__)"

5) enter bash shell: -> bash
   exit bash shell : -> exit

6) check linus release information
-> cat /ect/os-release

7) the problem no module scipy.misc has imresize function in our gpu machine:
my solution: python3.7 -m pip install scipy==1.1.0 --user

8) monitor GPU usage:
->watch -d -n 0.5 nvidia-smi

8) how to check cuda, or cudnn verion, please see:
https://medium.com/@changrongko/nv-how-to-check-cuda-and-cudnn-version-e05aa21daf6c

9) how to check the version of toolbox installed with python? type the following for python3.5 in the shell:
pip3.5 list

--------------------------------------------------------------------------------------------------------------------
1). to check GPU information from command line:
>>nvidia-smi

2). to check tensorflow version:
>>python -c 'import tensorflow as tf; print(tf.__version__)'

3). to test if GPU machine supports GPU computation:
>>python 3.5 testGPU.py

where testGPU.py has following codes:

import tensorflow as tf
from tensorflow.python.client import device_lib

def get_available_gpus():
    local_device_protos = device_lib.list_local_devices()
    return [x.name for x in local_device_protos if x.device_type == 'GPU']

if __name__=='__main__':
    print(tf.__version__)
    name = get_available_gpus()
    print("GPUS:{}".format(name))
    
 The outputs:...GPUS:['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3']
 
 __________________________________________________________________________________________
 1. run python program and load parameters from a file:
 
 >>python3.7 main_msi_tcga.py @./tests/config.txt    
